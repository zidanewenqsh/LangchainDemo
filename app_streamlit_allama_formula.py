import os
from dotenv import load_dotenv
import streamlit as st
from langchain_community.llms import Ollama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import logging
import sys
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time
import re

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('streamlit_app.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# é…ç½® requests çš„é‡è¯•ç­–ç•¥
session = requests.Session()
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[429, 500, 502, 503, 504],
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session.mount("http://", adapter)
session.mount("https://", adapter)

def render_latex(text):
    """å¤„ç†æ–‡æœ¬ä¸­çš„ LaTeX å…¬å¼ï¼Œç¡®ä¿æ­£ç¡®æ¸²æŸ“"""
    # ä¿æŠ¤ä»£ç å—ä¸­çš„å†…å®¹
    code_blocks = {}
    code_block_count = 0
    code_pattern = re.compile(r'```.*?```', re.DOTALL)
    
    def save_code_block(match):
        nonlocal code_block_count
        placeholder = f"CODE_BLOCK_{code_block_count}"
        code_blocks[placeholder] = match.group(0)
        code_block_count += 1
        return placeholder
    
    # æš‚æ—¶ä¿å­˜ä»£ç å—
    text = code_pattern.sub(save_code_block, text)
    
    # ä¸éœ€è¦æ›¿æ¢æ•°å­¦ç¬¦å·ï¼Œä¿æŒåŸå§‹çš„ $ å’Œ $$ ç¬¦å·
    # åªéœ€è¦ç¡®ä¿å®ƒä»¬åœ¨æ­£ç¡®çš„ä½ç½®
    
    # æ¢å¤ä»£ç å—
    for placeholder, code_block in code_blocks.items():
        text = text.replace(placeholder, code_block)
    
    return text

def format_message(text):
    """æ ¼å¼åŒ–æ¶ˆæ¯ï¼Œå¤„ç†ç‰¹æ®Šæ ¼å¼"""
    if not text:
        return ""
    
    # å¤„ç† LaTeX å…¬å¼
    text = render_latex(text)
    
    # å¤„ç†ä»£ç å—æ ¼å¼
    lines = text.split('\n')
    formatted_lines = []
    in_code_block = False
    
    for line in lines:
        if line.startswith('```'):
            in_code_block = not in_code_block
            if in_code_block:
                formatted_lines.append('<pre><code>')
            else:
                formatted_lines.append('</code></pre>')
        else:
            if in_code_block:
                formatted_lines.append(line.replace('<', '&lt;').replace('>', '&gt;'))
            else:
                # å¤„ç†è¡Œå†…å…¬å¼ï¼Œå°† \( \) è½¬æ¢ä¸º $ $
                line = re.sub(r'\\\\?\(', '$', line)
                line = re.sub(r'\\\\?\)', '$', line)
                # å¤„ç†è¡Œé—´å…¬å¼ï¼Œå°† \[ \] è½¬æ¢ä¸º $$ $$
                line = re.sub(r'\\\\?\[', '$$', line)
                line = re.sub(r'\\\\?\]', '$$', line)
                formatted_lines.append(line)
    
    # ç›´æ¥è¿”å›æ ¼å¼åŒ–çš„æ–‡æœ¬
    return '\n'.join(formatted_lines)

def check_ollama_service():
    """æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€"""
    try:
        response = session.get(
            "http://localhost:11434/api/version",
            timeout=5
        )
        is_running = response.status_code == 200
        logger.info(f"Ollama æœåŠ¡çŠ¶æ€æ£€æŸ¥: {'è¿è¡Œä¸­' if is_running else 'æœªè¿è¡Œ'}")
        return is_running
    except Exception as e:
        logger.error(f"æ£€æŸ¥ Ollama æœåŠ¡æ—¶å‡ºé”™: {str(e)}")
        return False

def get_available_models():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        response = session.get(
            "http://localhost:11434/api/tags",
            timeout=5
        )
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [model['name'] for model in models]
            logger.info(f"å¯ç”¨æ¨¡å‹åˆ—è¡¨: {model_names}")
            return model_names
        return []
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        return []

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
logger.info("ç¯å¢ƒå˜é‡åŠ è½½å®Œæˆ")

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Ollama AI åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– MathJaxï¼ˆåªåœ¨é¦–æ¬¡åŠ è½½æ—¶ï¼‰
if "mathjax_loaded" not in st.session_state:
    st.session_state.mathjax_loaded = True
    st.markdown("""
    <script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\\\(', '\\\\)']],
            displayMath: [['$$', '$$'], ['\\\\[', '\\\\]']],
            processEscapes: true,
            processEnvironments: true,
            packages: ['base', 'ams', 'noerrors', 'noundefined']
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            ignoreHtmlClass: 'tex2jax_ignore',
            processHtmlClass: 'tex2jax_process'
        },
        loader: {
            load: ['[tex]/noerrors', '[tex]/noundefined']
        },
        startup: {
            typeset: true
        }
    };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    """, unsafe_allow_html=True)

# æ·»åŠ  CSS æ ·å¼
st.markdown("""
<style>
    .math-content {
        font-size: 1em;
        line-height: 1.6;
    }
    .math-content p {
        margin: 1em 0;
    }
    .MathJax {
        font-size: 1.1em !important;
    }
    mjx-container {
        overflow-x: auto;
        overflow-y: hidden;
        padding: 0.5em 0;
    }
    mjx-container[jax="CHTML"][display="true"] {
        margin: 1em 0;
        text-align: center;
    }
    pre code {
        display: block;
        padding: 1em;
        background-color: #f6f8fa;
        border-radius: 4px;
        overflow-x: auto;
        font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
    }
</style>
""", unsafe_allow_html=True)

st.title("Ollama AI åŠ©æ‰‹")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
    logger.info("åˆå§‹åŒ–ä¼šè¯çŠ¶æ€")

# ä¿®æ”¹åˆå§‹åŒ–éƒ¨åˆ†
if "selected_model" not in st.session_state:
    st.session_state.selected_model = None

# åœ¨ä¾§è¾¹æ æ·»åŠ æ¨¡å‹é€‰æ‹©
with st.sidebar:
    st.subheader("ç³»ç»ŸçŠ¶æ€")
    if check_ollama_service():
        st.success("Ollama æœåŠ¡è¿è¡Œæ­£å¸¸")
        # è·å–å¹¶æ˜¾ç¤ºå¯ç”¨æ¨¡å‹åˆ—è¡¨
        available_models = get_available_models()
        if available_models:
            selected_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                available_models,
                index=None,
                placeholder="è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹"
            )
            if selected_model != st.session_state.selected_model:
                st.session_state.selected_model = selected_model
                st.session_state.messages = []  # æ¸…é™¤å†å²æ¶ˆæ¯
                st.rerun()
        else:
            st.error("æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼Œè¯·å…ˆå®‰è£…æ¨¡å‹")
            st.stop()
    else:
        st.error("Ollama æœåŠ¡æœªè¿è¡Œ")

    # æ·»åŠ æ¸…é™¤æŒ‰é’®
    if st.button("æ¸…é™¤å¯¹è¯å†å²"):
        st.session_state.messages = []
        logger.info("å¯¹è¯å†å²å·²æ¸…é™¤")
        st.rerun()

    # æ·»åŠ è°ƒè¯•ä¿¡æ¯æ˜¾ç¤º
    if st.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"):
        st.subheader("è°ƒè¯•ä¿¡æ¯")
        st.write("å½“å‰æ¨¡å‹:", st.session_state.selected_model)
        st.write("ä¼šè¯æ¶ˆæ¯æ•°:", len(st.session_state.messages))
        
        if st.button("æ£€æŸ¥æœåŠ¡çŠ¶æ€"):
            if check_ollama_service():
                st.success("æœåŠ¡æ­£å¸¸")
            else:
                st.error("æœåŠ¡å¼‚å¸¸")

    # æ·»åŠ  LaTeX æ”¯æŒè¯´æ˜
    with st.expander("æ•°å­¦å…¬å¼æ”¯æŒè¯´æ˜"):
        st.markdown("""
        æœ¬åŠ©æ‰‹æ”¯æŒæ•°å­¦å…¬å¼æ¸²æŸ“ï¼š
        
        1. è¡Œå†…å…¬å¼ï¼šä½¿ç”¨å•ä¸ª `$` ç¬¦å·
           ä¾‹å¦‚ï¼š$E=mc^2$
        
        2. å…¬å¼å—ï¼šä½¿ç”¨ä¸¤ä¸ª `$$` ç¬¦å·
           ä¾‹å¦‚ï¼š
           $$
           F = ma
           $$
           
        3. å¤æ‚å…¬å¼ï¼š
           $$
           \oint_{\partial \Omega} \mathbf{E} \cdot d\mathbf{S} = \frac{1}{\epsilon_0} \int_{\Omega} \rho dV
           $$
        """)

# ä¿®æ”¹èŠå¤©å†å²æ˜¾ç¤ºéƒ¨åˆ†
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        formatted_content = format_message(message["content"])
        st.markdown(formatted_content, unsafe_allow_html=True)

# è·å–ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    logger.info(f"æ”¶åˆ°ç”¨æˆ·è¾“å…¥: {user_input}")
    
    # æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€
    if not check_ollama_service():
        st.error("Ollama æœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡")
        logger.error("å°è¯•ç”Ÿæˆå›å¤æ—¶å‘ç° Ollama æœåŠ¡æœªè¿è¡Œ")
        st.stop()
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # æ·»åŠ åŠ©æ‰‹å“åº”
    with st.chat_message("assistant"):
        try:
            message_placeholder = st.empty()
            
            with st.status("æ­£åœ¨ç”Ÿæˆå›å¤...", expanded=True) as status:
                st.write("æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...")
                logger.info("å¼€å§‹ç”Ÿæˆå›å¤...")
                
                try:
                    if not st.session_state.selected_model:
                        st.info("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
                        st.stop()
                        
                    # åˆå§‹åŒ– LLM å’Œæç¤ºæ¨¡æ¿
                    llm = Ollama(
                        model=st.session_state.selected_model,
                        temperature=0.7,
                        base_url="http://localhost:11434",
                        timeout=120
                    )
                    
                    # åˆ›å»ºæç¤ºæ¨¡æ¿
                    prompt = ChatPromptTemplate.from_messages([
                        ("system", """ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œæ“…é•¿ç”¨ç®€æ´çš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
                        - ä½¿ç”¨ Markdown æ ¼å¼æ¥ç»„ç»‡ä½ çš„å›ç­”
                        - å¯¹äºæ•°å­¦å…¬å¼ï¼š
                          * è¡Œå†…å…¬å¼ä½¿ç”¨ $ ç¬¦å·ï¼Œå¦‚ $E=mc^2$
                          * ç‹¬ç«‹å…¬å¼å—ä½¿ç”¨ $$ ç¬¦å·ï¼Œå¦‚ï¼š
                            $$
                            F = ma
                            $$
                        - é‡è¦å†…å®¹ä½¿ç”¨ **åŠ ç²—** æˆ– *æ–œä½“*
                        - ä½¿ç”¨åˆ—è¡¨å’Œè¡¨æ ¼æ¥ç»„ç»‡ä¿¡æ¯
                        - ä»£ç ç‰‡æ®µä½¿ç”¨ä»£ç å—æ ¼å¼
                        """),
                        ("human", "{input}")
                    ])
                    
                    # åˆ›å»ºå¤„ç†é“¾
                    chain = prompt | llm | StrOutputParser()
                    
                    # ä½¿ç”¨å®é™…çš„ç”¨æˆ·è¾“å…¥ç”Ÿæˆå›å¤
                    response = chain.invoke({"input": user_input})
                    
                    # æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ
                    full_response = ""
                    for char in response:
                        full_response += char
                        formatted_response = format_message(full_response)
                        message_placeholder.markdown(
                            formatted_response,
                            unsafe_allow_html=True
                        )
                        time.sleep(0.01)
                    
                    status.update(label="å›å¤ç”Ÿæˆå®Œæˆ!", state="complete")
                    logger.info(f"æˆåŠŸç”Ÿæˆå›å¤: {response[:100]}...")
                    
                except Exception as e:
                    status.update(label="ç”Ÿæˆå›å¤å‡ºé”™", state="error")
                    raise e
            
            # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.messages.append({"role": "assistant", "content": response})
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg, exc_info=True)
            st.error(error_msg)
            
            if st.button("é‡è¯•"):
                st.rerun()

# æ·»åŠ é¡µè„šï¼ŒåŒ…å« LaTeX ç¤ºä¾‹
st.markdown("---")
st.markdown("""
powered by Ollama & LangChain ğŸš€

ç¤ºä¾‹é—®é¢˜ï¼š
1. è¯·è§£é‡Šä¸€ä¸‹è´¨èƒ½æ–¹ç¨‹ $E=mc^2$
2. å†™å‡ºç‰›é¡¿ç¬¬äºŒå®šå¾‹çš„æ•°å­¦è¡¨è¾¾å¼
3. è®¡ç®—åœ†çš„é¢ç§¯å…¬å¼æ¨å¯¼
4. è§£é‡Šéº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ç»„
""") 